\documentclass[11pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage[norsk]{babel}


\begin{document}
\title{Hovedprosjekt 08}
\author{M Byhring, T E Iversen, L M Bredal\\
Høgskolen i Oslo, avdeling for ingeniørutdanning}
\renewcommand{\today}{26 februar, 2008}
\maketitle


\newpage 
\tableofcontents
\section{Innledning}
Her vil det komme en innledning etter hvert\\

LCFG er et system ++++

\section{Hoveddel}

\subsection{Innledning}
Det kan tenkes at innledningen på Hoveddelen ikke får noen tittel, slik som den har nå. Vi får se.

\subsection{Planlegging og metode}

\subsubsection{Profilfilene}
Grunnlaget for prosjektet er en samling av filer i XML-format (Extensible Markup Language), der hver fil representerer konfigurasjonen til en maskin. Disse filene kan endres over tid, slik at det er mulig å lage en historikk over endringer i konfigurasjonsprofilen dersom man tar vare på gamle data.
\\\\\noindent
Første fase av projektet gikk i stor grad ut på å få en oversikt over strukturen på filene og hvilke data vi hadde tilgjengelig. Vi startet med en samling på 1060 XML-filer med en gjennomsnittlig størrelse på omkring 1MB. Første skritt var å fjerne en del data som av oppdragsgiver var angitt som uinteressante for oss, da de kun var bergnet på feilsøking. Dette medførte en halvering av datamengden.
\\\\\noindent
Vi kunne nå begynne å skaffe oss et bilde av datagrunnlaget ved å ta for oss en av filene og se på strukturen. Etter å ha fått en viss oversikt over strukturen kunne vi lage script for å hente ut den informasjonen vi ønsket fra alle filene for å skaffe oss en total oversikt over materialet. 
\\\\\noindent
Neste skritt i prosessen med å velge ut hvilke data vi ville jobbe videre med var å finne ut hva de egentlig representerte. I dette arbeidet benyttet vi oss av dokumentasjonen til LCFG for å finne ut hva de enkelte verdiene representerte. Det viste seg etterhvert at denne dokumentasjonen var forholdsvis mangelfull, men  den var likevel til stor hjelp. Det viste seg blant annet at en del datafelter vi i utgangspunktet hadde antatt var interessante, likevel ikke hadde den betydningen vi trodde at de hadde.
\textbf{(eksempler?)}
\\\\\noindent
En oppsummering av oppbyngningen av XML-filene:
\begin{itemize}
  \item profilen består av to hovedseksjoner: components og packages
  \item seksjonen components inneholder en rekke underseksjoner som representerer konfigurasjonen av et program, eller tjeneste (komponent) på maskinen
  \item en komponent kan inneholde både andre underseksjoner og bladnoder som inneholder informasjon.
  \item det er tilsammen 111 forskjellige 'components' i datamaterialet vårt
  \item det er kun 'profile'-komponenten som må være med i componentsseksjonen
\end{itemize}

TODO:
Flere seksjoner:

\subsubsection{Verktøy}
Tidlig i prosjektprosessen hadde vi møte med veileder hvor vi diskuterte hvilke teknologier vi burde bruke til å gjennomføre vårt prosjekt. Vi trengte et programmeringsspråk som er ekstra kjapt og hendig med XML-data (Extensible Markup Language), et som egner seg til å ekstrahere ut data fra en DB, et som egner seg til å generere filer og et språk som skal brukes til å visualisere hundrevis av noder i et tredimensjonalt rom. Etter råd fra veileder var det klart hvilke to språk som skulle være våre hovedverktøy; Perl og VRML (Virtual Reality Modeling Language). Perl er ypperlig til å innsette og ekstrahere data, og til å generere *.wrl-filer. Slik vi har tenkt oss å visualisere konfigurasjonen i LCFG, vil VRML fylle alle våre krav til framvisning av dette.
\\\\\noindent 
Når vi startet prosjektet hadde gruppen noe erfaring med Perl. Bruksområdene til Perl i vårt prosjekt vil være ekstrahering av data fra XML og database, og generering av filer. Det vi tidligere har gjort i Perl , mens vi nå jobber mot XML, database og generering av filer. Siden vi alle på gruppen har jobbet litt med Perl, har det ikke vært noen stor jobb å tilegne seg mer kunnskap i disse områdene.
\\\\\noindent  
VRML har en relativt enkel syntaks, som ligner noe på ett oppmerkingsspråk. Dette vil si at man for det meste deklarer noder, og gir den forskjellige attributter med verdier som forteller hvor de respektive nodene skal være på skjermen. Det elementære i VRML gikk dermed fort å lære, men vi har brukt lengre tid på å få til de mer avanserte delene av VRML, som ruter, interpolatorer og trykksensorer. VRML har også en del avanserte felter som vi måtte lære hva gjorde og hvordan bruke dem, og disse har en annerledes syntaks enn noe vi har vært borte i før. Vi brukte utviklingsmiljøet VRMLPad til å eksperimentere og forske på disse, slik at vi kunne tilegne oss nok kunnskap til å senere bruke disse feltene.
\\\\\noindent  
For å tolke XML-filene, trenger vi moduler som kan hjelpe Perl til å skjønne XML-struktur slik at vi får de dataene vi vil ha. Vi valgte først å bruke DOM (Document Object Model) til å tolke disse filene. Denne modulen er noe vi hadde liten forkunnskap om, så vi måtte tilbringe en god stund foran manualer for å forstå hvordan vi skulle ekstrahere data med den. Når vi ble godt kjent med syntaksen lagde vi et testskript i Perl, som skulle parse alle filene. DOM viste seg å være veldig treg med alle filene vi skal parse, og minneforbruket var så stort at våre maskiner kræsja. Vi løste midlertidig problemet, ved å  Vi søkte etter en ny modul, og fant LibXML som innfridde de forventninger vi har til en XML-parser. Dette er en XML parser til Gnome biblioteket (et Unix-grensenitt), og viste seg å være utrolig kjapp. Syntaksen på XML-spørringene er litt annerledes fra DOM, så noe omskriving måtte til. Som nevnt trenger vi å parse et stort antall XML-filer og LibXML viste seg å være raskere og mer effektiv enn DOM. Vi testet de to forskjellige modulene på vårt datasett, og det viste seg at LibXML er ca ti ganger kjappere, og brukte ca. en prosent av systemminne, mens DOM forsynte seg av rundt 70 - 80 prosent. 
\\\\\noindent 
DBI (Database Interface) er et databasegrensesnitt for Perl, som vi valgte å bruke for å lage og eksekvere spørringer til en database. Vi hadde liten forkunnskap om modulen, men syntaksen var lett å skjønne. Alle på gruppen har hatt et relasjonsdatabasefag, og vi ble enige om at MySQL (My Structured Query Language) skal være vårt databasespråk. Dette fordi vi er familiære med syntaksen og skolen tilbyr gratis MySQL-servere. DBI-modulen kobler opp mot en MySQL-database på en enkel måte, og spørringer og svar er enkelt å fremstille og hente.
\\\\\noindent 
Som programmerings-IDE har vi valgt å bruke eclipse, med tilleggsmodulene EPIC (Eclipse Perl Integration) og subclipse (SVN).
Dette fordi det er et godt utviklingsmiljø til Perl, og det gir støtte for subversion.
\\\\\noindent
Som dokumentasjonsverktøy har vi valgt å bruke \LaTeX{} etter å ha fått dette anbefalt av veileder. Ved å skrive dokumentasjonen i Latex er vi helt sikre på at teksten blir formattert på ønskelig måte.
\subsubsection{Faglige forutsetninger}
AlgDat - algoritmer
[TODO: Finne fram noen fine algoritmer fra prosjektet, og relatere dem til algoritmer og datastrukturer]	
\\\\\noindent
Siden vi har måttet tilegne oss mye ny kunnskap om forskjellige språk og moduler, og vi har måttet lære oss syntaks så fort som mulig har alle tidligere programmeringsfag vi har hatt hjulpet oss med dette. Siden vi da har vært borti flere typer språk, har vi en lettere forståelse for generell programmering og dette har hjulpet oss i å forstå Perl, VRML og de respektive modulene mye kjappere enn hvis vi ikke hadde hatt noen av disse fagene. Sett bort i fra de rene programmeringsfagene, er det to fag som har bedret vår forståelse av komponentene i profilfilene; Operativsystemer og Unix, og Nettverks- og Systemadministrasjon. Våre XML-profiler kan inneholde flere hundre tjenester og konfigurasjoner i form av komponenter, og de to fagene nevnt har lært oss mye akkurat dette. Dette har gjort at vi har lettere fått en god forståelse av hva profilfilene sier, og gjort det lettere for oss å velge ut komponenter til visualisering. For eksempel forteller noen av profilfilene at de er Apache- eller PostgreSQL-servere, og uten fagene hadde vi hatt liten kunnskap om hva dette sto for. 
\\\\\noindent
Relasjonsdatabasefaget har gitt oss grunnleggende kunnskap om databaser, da i sær MySQL og databasedesign. Normalisering av tabeller, og avanserte spørringer til en MySQL-database er viktig og relevant i forhold til vårt prosjekt, og det er noe av det vi lærte i dette faget.
\\\\\noindent
\subsubsection{Hva måtte vi lære oss}
[TODO: Fjerne dette avsnittet?]

\subsubsection{Databasestruktur}
Vi har valgt å benytte mySQL som database.
Etter å ha analysert XML-filene, kom vi fram til at det ville være hensiktsmessig å opprette en tabell for hver konfigurasjonsBit (TODO: endre dette til et bedre ord) som vi ønsker å bruke i  components-delen.
Et eksempel: i XML-profile-filene har vi som oftest en konfigurasjonsdel $ <network> $.
Vi genererer da en tabell network, med de feltene vi ønsker å benytte oss av.
Som oftest er dette string-felter eller boolske verdier.
Primærnøkkelen i disse komponent-tabellene vil være maskinnavn, samt dato, da konfigurasjonen kan endres over tid og vi ønsker å ta vare på endringer i konfigurasjon.


I noen tilfeller vil denne strukturen ikke være gunstig, slik at noen tabeller vil være bygget opp på en annen måte. TODO: sette inn eksempel på dette...\\


Vi ønsker også at systemet skal være utvidbart, så det bør være relativt enkelt for sluttbruker å velge nye felter i XML-profilene som utvider eksisterende tabeller, eller oppretter nye dersom tabellen ikke eksistererer.

 \subsubsection{Hendelsesflyt for import til DB}

 Leser inn cfg fil
 cfg-fila skal inneholde:
 Databaseinformasjon (username, pass, host, port, type of base)
 Tabell- og kolonnenavn (inv / os) - attributt
 Namespace over xml-filene
 Path til zip-fil over profiler

 Tester databasetilkobling med parametre fra cfg

 Zipper opp profiler og legger de i en temporær katalog

 Deklarer en array over tabell (hovedkomponenter - eksempel inv)
 Og i denne arrayen må det legges flere nye hasher over kolonnenavn (eksempel inv/os)
 Deklarer også en boolsk array over tabellene, som senere vil si i fra om operasjonenene har gått bra eller ikke
 Hvis det er noen som ikke har gått OK, så kopiereres ikke tabellene tilbake.

 Opprett tabeller med kolonnenavn hentet fra cfg
 Hvis tabell eksisterer fra før av og kolonnenavnene ikke samsvarer:
 Kopier tabell og alter.
Denne nye tabellen skal det legges data i, og senere skal den overskrive den gamle
 Hvis tabell eksisterer fra før av og kolonnenavnene samsvarer:
 Append table.

 Løpe i gjennom filer ( foreach <>)
     Deklarer man rotnode, etc
     Finne $ "last_modified" $ og legge den i en variabel
     sub getLastModified(maskinnavn)
     Hvis $ last_modified $ fra xml er nyere enn den i DB, fortsett
     Opprett en boolsk variabel som skal holde rede på om det blir gjort noen forandringer, \$changed
   
     Løpe i gjennom tabellparametre (hovedkomponenter)

         Sjekke om parameteren eksisterer i xml-filen
         Bør sjekke nivået på parameteren som kommer inn, og at det i hele tatt er verdi der.

         Finne ut verdien til parameteren, og legger denne som en value til tilhørende key i hash (f.eks. "fc6" til inv/os)
         Ikke glem attributten hvis vi skal ha den.
   
         Hvis databasen allerede eksisterte, må vi selecte fra databasen alle dataene fra den maskinen vi holder på med
         og sjekke mot hashen om det er noen nye verdier.
         Hvis det er det, så må vi inserte en ny rad og gi \$changed verdien "true".
       
       
       
     Sjekke \$changed
     Hvis "true"
     Oppdatere tabell $ last_modified med last_modified $

     Sjekke om det er noen false-verdier i den boolske arrayen
     Overskrive de gamle tabellene hvis alle er OK.
       
       
sub getLastModified
{
    my \$tempMachine = shift  ;
   
     Hente ut fra DAL last modified fra denne maskinen
     Returnere denne
}

 TODO:
 Lag en tabell $ last_modified $, som inneholder id, maskinnnavn og lastmodified
 Denne må oppdateres hver gang det blir gjort en endring

 Logge alle aktiviteter/forandringer som skjer ved hjelp av dette scriptet
 For eksempel, antall rader forandret, mange filer som var helt like, etc etc

**TODO: Sette inn ER-diagram.***

\subsubsection{Visualisering}
Hvorfor og hvordan
Visualiseringstyper - hvilke vi tror vi kommer til å bruke

En oppgave vi hadde var å prøve ut ulike visualiseringsteknikker, for å se hvilke som kunne passe til forskjellige data.

Resultatet vil bli en visualisering av forskjellige grupper ( clustere ) av datamaskiner, heretter kalt noder, der nodenes konfigurasjons(u)likhet kommer klart frem, for eksempel gjennom nodenes form, farge og posisjoner i et tredimensjonalt rom.


For å få litt inspirasjon, pekte vår veileder oss til en masteroppgave (TODO: link, referanse) der det var presentert mange forskjellige måter å visualisere data på. 
Noen teknikker vi ønsker å prøve er blant annet:\\
\begin{itemize}

\item \textbf{Information pyramids} 
Her vises informasjon i flere lag som et hierarki. 
Eksempelvis kan man tegne opp et lag underst som representerer alle noder, neste lag kan bestå av noder som oppfyller et bestemt kriterie, og neste lag igjen et videre sub-utvalg av disse igjen.
Det er da mulig å for eksempel få et inntrykk av hvor mange noder som oppfyller forskjellige kriterier.
\item \textbf{Scatter plot}
Dette består av noder som er spredt rundt i et område. 
Posisjonen til en node kan fortelle noe om nodens egenskaper, litt som en graf.
\item \textbf{Heatmaps}
Ved å gruppere alle noder inn i en "klump", og deretter fargelegge deler som oppfyller et kriterie, vil man kunne få noe som minner om et kart som viser geografi / topografi. 
\item \textbf{Tree visualization}
Kan vise nodens indre struktur, mulig å sammenligne to eller flere trær.
Jfr. nodenes struktur, vil dette ikke være et typisk binærtre.
En mulighet vil også være å forsøke å visualisere en eller flere "standard-noder" basert på statistisk analyse av dataene, og så sammenligne enkeltnoder opp mot standarden.
\end{itemize}
Vi ønsker å forsøke å kombinere flere av disse teknikkene der dette er mulig, for å 
kunne trekke ut informasjon og sammenhenger som er vanskelig å finne ut av ellers.\\\\\noindent
Hva skal vi visualisere?\\\\\noindent
Dette var noe vi måtte bruke en del tid på å finne ut.
For det første trengte vi å få oversikt over dataene, for å se hva de representerte.
Etter hvert ble det klart at for å avgrense oppgaven, begrenset vi oss til components-seksjonen i filene.
\textbf{TODO: Flytte dette opp i XML-fil delen?}
Til å hjelpe oss å analysere, laget vi et perl-script som ved hjelp av libXML gikk gjennom alle profil-filene, og fant antallet forskjellige komponenter, samt hvor mange maskiner som hadde disse.
Dette gjorde det enklere å få oversikt over hvilke komponenter som var i bruk.
Etter at vi hadde lest gjennom dokumentasjonen over komponentene (link?) og sett hvilke parametere som var vanlige, satte vi opp en liste over hvilke aktuelle felter i samarbeid med oppdragsgiver / veileder.
Disse var i første omgang:
\textbf{Note to self: Skal denne listen være her???}
\begin{itemize}
\item inv / os -$>$ Operativsystem
\item inv / manager -$>$ Ansvarlig administrator
\item profile / group -$>$ Gruppen som maskinen hører til. Kan si noe om funksjonen til maskinen
\item inv / location -$>$ Fysisk lokasjon
\item xinetd / enableservices -$>$ Tjenester som benyttes av xinet.d. Ikke mange profiler som har denne.
\item apache -$>$ Betyr at maskinen kjører en webservertjeneste. Kun 17 av 43 har apacheconfig
\item mysql -$>$ Betyr at maskinen har mysql daemon kjørende
\item dhcpd -$>$ Betyr at maskinen kjører en dhcpdaemon
\item postgresql -$>$ Betyr at maskinen har en postgresql daemon kjørende
\item rsync -$>$ Betyr at maskinen har en rsync tjeneste oppe
\item subversion/cvs -$>$ subversion tjeneste kjører
\item samba -$>$ sambaserver kjører
\item inv / model -$>$ forteller om maskinmodellen (eks: Dell OptiPlex 9700)
\item network / gateway -$>$ default gateway for maskinen.
\end{itemize}


\subsection{Utviklingsprosessen}
\subsubsection{Faser}
Fasene i prosjektet fulgte RUP-fasene. (?)\\
Innledning\\
Utforming\\
Bygging\\
Overgang\\

\subsubsection{Oppbygging av programmet}
Programmet består av to hoveddeler: dataImport og dataVisualiserer.
todo: sette inn bilde
dataImport-delen er ansvarlig for å lese inn nye datasett i form av XML-filer, og ekstrahere de feltene vi ønsker å trekke ut, for så å legge disse inn i database. Denne delen er så delt opp i moduler for hver komponent som skal trekkes ut, dette for å gjøre det enkelt å utvide importen til å gjelde flere komponenter / felter. Forhåpentligvis gjør dette også det lettere å endre konfigurasjonen til å kunne importere andre XML-filer, dersom andre senere vil importere andre typer filer.\\\\\noindent
dataVisualiserer-delen har ansvaret for å hente data fra databasen og generere VRML som så blir presentert for brukeren. 
Vi har valgt å implementere en 3-lags struktur med DAL ( Data Access Layer) for database-tilkobling, BLL (Business Logic Layer) for generering av VRML, og GUI (Graphical User Interface)  for kommunikasjon / presentasjon for sluttbruker.
Dette er gjort for å gjøre systemet utvidbart og generisk - eksempelvis vil det være mulig å gå over til en annen databasemotor ved kun å endre / bytte ut DAL.
Vi har valgt å implementere GUI som en Web-applikasjon, da kombinasjonen *AMP (Apache, MySQL, Perl) er en god og plattformuavhengig kombinasjon, samt at det ikke stiller store krav til klienten, som egentlig kun trenger å kunne vise HTML, javascript og VRML.

Også DAL og BLL er delt opp i mindre moduler for å gjøre det enkelt å legge til funksjonalitet, vi tilbyr ferdige skeleton-filer som kan modifiseres til å relativt enkelt inkludere ny funksjonalitet.

\subsubsection{Strukturen i gruppa}
 - miljø, arbeidsgiver, veileder
\subsubsection{Metodikk / prosessmodell}
Gruppen bestemte seg tidlig for å benytte seg av en smidig utviklingsprosess, med mange iterasjoner og konstant utvikling av kravspesifikasjonene.
Vi valgte å bruke RUP som prosessmodell, med innslag av XP.
XP-elementer ble valgt blant annet fordi vi måtte komme raskt i gang med programmeringen, for å gjøre oss kjent med språkene, vi synes også parprogrammering kan være gunstig innimellom.

\subsubsection{Hva var X-tra vanskelig?}


\subsection{Kravspesifikasjon}
\begin{itemize}
	\item Hva har den betydd, og hvilken rolle har den spilt for utviklingen.\\
I begynnelsen hadde vi en svært løs kravspesifikasjon.
Underveis i prosjektperioden la vi til nye krav og raffinerte de eksisterende kravene, i samarbeid med oppdragsgiver.
Dette ble gjort fordi vi trengte kunnskap om både verktøyene og konfigurasjonsfilene, for å kunne sette realistiske krav, som vi så forsøkte å innfri så raskt som mulig, før vi gikk en ny runde med videreutviklingen av kravene våre.

	\begin{itemize}
		\item gruppa
		\item produkt 
\end{itemize}
	\item Endringer ....
\end{itemize}

\subsection{Resultat}
Tolking av resultatet.

\section{Avslutning}

\begin{itemize}
	\item Eget utbytte
	\item Oppsummering
	\item Konklusjoner
	\item Refleksjoner - Hva kunne vært gjort annerledes
	\item Hva kan det brukes til? Fremtid
	\item Hva syns oppdragsgiver om produktet vårt?
	\item Skal det brukes videre?
\end{itemize}


\end{document}
